{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "# Checking Tensorflow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 14s 1us/step\n"
     ]
    }
   ],
   "source": [
    "#Loading data from keras API\n",
    "(X_train, y_train ), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of train values\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of X_train\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x248469b6088>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Viewing the values in train\n",
    "plt.matshow(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the values\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "#Flattening to single layer stack\n",
    "X_train_flattened = X_train.reshape(len(X_train), 28*28)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 28*28)\n",
    "print(X_test_flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.4866 - accuracy: 0.8786\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3059 - accuracy: 0.9154\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2855 - accuracy: 0.9206\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2750 - accuracy: 0.9239\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2676 - accuracy: 0.9263\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2626 - accuracy: 0.9271\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2589 - accuracy: 0.9288\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2554 - accuracy: 0.9296\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2529 - accuracy: 0.9305\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2499 - accuracy: 0.9311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24845ad8248>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a simple model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape = (784,), activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "\n",
    ")\n",
    "\n",
    "model.fit(X_train_flattened, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 89us/sample - loss: 0.2616 - accuracy: 0.9282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26156347406804564, 0.9282]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model performance using test values\n",
    "model.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x248630204c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3770623e-04, 7.8728397e-07, 6.9013935e-01, 3.1738229e-05,\n",
       "       1.9904908e-15, 3.2143430e-03, 2.4363897e-03, 1.7955062e-19,\n",
       "       3.3673066e-05, 1.3597800e-16], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting the values\n",
    "y_pred = model.predict(X_test_flattened)\n",
    "y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 2, 1, 0, 4]\n"
     ]
    }
   ],
   "source": [
    "#Printing indices of array\n",
    "y_pred_labels = [np.argmax(i) for i in y_pred]\n",
    "print(y_pred_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[ 958,    0,    2,    2,    0,    7,    6,    2,    3,    0],\n",
       "       [   0, 1106,    5,    2,    0,    1,    4,    2,   15,    0],\n",
       "       [   3,    7,  928,   14,    8,    5,   12,    9,   43,    3],\n",
       "       [   2,    0,   20,  916,    1,   29,    2,    9,   25,    6],\n",
       "       [   1,    1,    5,    1,  929,    0,    7,    4,    8,   26],\n",
       "       [   6,    2,    1,   27,   10,  794,   12,    4,   32,    4],\n",
       "       [  10,    3,    9,    1,    7,   18,  906,    1,    3,    0],\n",
       "       [   1,    6,   25,    4,   10,    2,    0,  941,    2,   37],\n",
       "       [   4,    6,    6,   14,    9,   31,    7,    6,  883,    8],\n",
       "       [   9,    7,    1,    7,   32,    8,    0,   14,   10,  921]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "cm = tf.math.confusion_matrix(labels= y_test, predictions= y_pred_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2922 - accuracy: 0.9176\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1371 - accuracy: 0.9601\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.0988 - accuracy: 0.9710\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0779 - accuracy: 0.9763\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0633 - accuracy: 0.9809\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0520 - accuracy: 0.9837\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0432 - accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.0370 - accuracy: 0.9889\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0320 - accuracy: 0.9904\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0272 - accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24862e929c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a model with one hidden layer \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape = (784,), activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "\n",
    ")\n",
    "\n",
    "model.fit(X_train_flattened, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 53us/sample - loss: 0.0816 - accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08156320858114632, 0.9752]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[ 958,    0,    2,    2,    0,    7,    6,    2,    3,    0],\n",
       "       [   0, 1106,    5,    2,    0,    1,    4,    2,   15,    0],\n",
       "       [   3,    7,  928,   14,    8,    5,   12,    9,   43,    3],\n",
       "       [   2,    0,   20,  916,    1,   29,    2,    9,   25,    6],\n",
       "       [   1,    1,    5,    1,  929,    0,    7,    4,    8,   26],\n",
       "       [   6,    2,    1,   27,   10,  794,   12,    4,   32,    4],\n",
       "       [  10,    3,    9,    1,    7,   18,  906,    1,    3,    0],\n",
       "       [   1,    6,   25,    4,   10,    2,    0,  941,    2,   37],\n",
       "       [   4,    6,    6,   14,    9,   31,    7,    6,  883,    8],\n",
       "       [   9,    7,    1,    7,   32,    8,    0,   14,   10,  921]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = tf.math.confusion_matrix(labels= y_test, predictions= y_pred_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2904 - accuracy: 0.9194\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1367 - accuracy: 0.9597\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.0976 - accuracy: 0.9715\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.0767 - accuracy: 0.9769\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.0635 - accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.0524 - accuracy: 0.9843\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0439 - accuracy: 0.9863\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0367 - accuracy: 0.9887\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.0308 - accuracy: 0.9905\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.0261 - accuracy: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24865c8d108>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a model \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
